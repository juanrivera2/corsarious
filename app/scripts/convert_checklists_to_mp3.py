# -*- coding: utf-8 -*-
"""9(3)_Convert_the_checklists_in_Mongo_database_to_MP3_using_AI.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Tad0CU1W1dJGTpNNLnsdDFum0yzb00cA
"""

!pip install easyocr pdf2image pytesseract opencv-python-headless Pillow

import cv2
import numpy as np
from pdf2image import convert_from_bytes
from PIL import Image
import pytesseract
import easyocr
import os
from google.colab import drive

drive.mount('/content/drive')

"""cloning the git repository to get the popplelr file to work with PDFs"""

!git clone https://anongit.freedesktop.org/git/poppler/poppler.git

!apt-get install poppler-utils # Installs the poppler-utils package
!sudo apt install tesseract-ocr # Install Tesseract OCR engine
!sudo apt install libtesseract-dev
import os
os.environ['PATH'] += os.pathsep + os.path.expanduser("~/anongit/freedesktop.org/git/poppler/poppler/build/utils") # Adds the poppler utils path to the environment variable


# Step 4: Define the file path in Google Drive
pdf_file_path_drive = '/content/drive/MyDrive/1-1_219P1020_CNPI25E_Cleanliness_and_Drying_Summary_28210.pdf'  # Replace with your file path

# Step 5: Read the PDF file from Google Drive
with open(pdf_file_path_drive, "rb") as f:
    pdf_bytes = f.read()

# Convert PDF pages to images
pages = convert_from_bytes(pdf_bytes)
print(f"Converted {len(pages)} pages from the PDF to images.")

# Install Tesseract OCR engine
!sudo apt install tesseract-ocr
!sudo apt install libtesseract-dev


# Set Tesseract path for pytesseract
pytesseract.pytesseract.tesseract_cmd = r'/usr/bin/tesseract'  # Tell pytesseract where to find tesseract



# Step 6: Initialize OCR reader
reader = easyocr.Reader(['en'], verbose=False)
extracted_questions = []  # List to store extracted questions


# Step 7: Loop through each page to detect tables and extract text
for i, page in enumerate(pages):
    print(f"\nProcessing Page {i + 1}...")

    # Convert PIL image to OpenCV format
    img = np.array(page)
    img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)

    # Convert image to grayscale
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

    # Detect edges to locate tables
    edges = cv2.Canny(gray, 50, 150)
    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (2, 2))
    dilated = cv2.dilate(edges, kernel, iterations=1)

    # Find contours to detect table-like structures
    contours, _ = cv2.findContours(dilated, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

    for contour in contours:
        x, y, w, h = cv2.boundingRect(contour)

        # Filter for table size (adjust thresholds as needed)
        if w > 100 and h > 50:
            table_img = img[y:y + h, x:x + w]

            # Extract text using Tesseract OCR
            table_text = pytesseract.image_to_string(table_img)

            # Check if the table contains the keyword "test"
            if "task" in table_text.lower():
                # Display the table and extracted text
                print("Detected Table:")
                display(Image.fromarray(cv2.cvtColor(table_img, cv2.COLOR_BGR2RGB)))
                print("Extracted Text:")
                print(table_text)

                # Step 11: Split the extracted text into lines and append to the list
                lines = table_text.split("\n")
                questions = [line.strip() for line in lines if line.strip()]
                extracted_questions.extend(questions)

# The End: The code processes the PDF file from Google Drive, detects tables, and extracts text.

!pip install pydub gtts # Install pydub library

from pydub import AudioSegment # Import AudioSegment from pydub
from pydub.silence import split_on_silence #Import split_on_silence from pydub.silence

from gtts import gTTS
from pydub import AudioSegment
# Instead of importing Silence, use AudioSegment.silent() directly
# from pydub.generators import Silence # Remove this line

# ... (rest of your code) ...

# Step 12: Generate MP3 file with 5 seconds of silence between questions
if extracted_questions:
    print("\nGenerating MP3 file...")

    # Initialize an empty audio segment
    final_audio = AudioSegment.silent(duration=0)

    # Assign file_name here before the loop
    file_name = os.path.basename(pdf_file_path_drive)

    for question in extracted_questions:
        # Generate audio for the question
        tts = gTTS(text=question, lang='en')
        tts.save("temp.mp3")
        audio_segment = AudioSegment.from_file("temp.mp3")

        # Add the question audio and 5 seconds of silence to the final audio
        final_audio += audio_segment + AudioSegment.silent(duration=5000)  # Use AudioSegment.silent for silence

        # Create an MP3 file name based on the PDF file
        mp3_file_name = os.path.splitext(file_name)[0] + ".mp3"

        # Export the final audio
        final_audio.export(mp3_file_name, format="mp3")
        print(f"MP3 file '{mp3_file_name}' created successfully!")
    else:
        print("No questions found to convert to audio.")
